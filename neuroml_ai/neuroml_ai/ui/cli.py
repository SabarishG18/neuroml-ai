#!/usr/bin/env python3
"""
Main runner interface for nml-ai

File: neuroml_ai/cli.py

Copyright 2025 Ankur Sinha
Author: Ankur Sinha <sanjay DOT ankur AT gmail DOT com>
"""

import asyncio
import subprocess
from contextlib import chdir
from pathlib import Path

import httpx
import typer
from fastmcp import Client

from neuroml_ai.utils import check_api_is_ready

nml_ai_app = typer.Typer()


@nml_ai_app.command()
def nml_ai_cli(
    gui: bool = False,
    single_query: str = "",
):
    """NeuroML AI cli wrapper function"""
    print("*** NeuroML AI chat assistant ***")
    print("Please note that answers are generated by LLMs and may be incorrect.")
    print()
    print("Type 'quit' to exit.")
    print()
    print()

    if not gui:

        async def cli_main():
            """Cli main async"""
            from yaspin import yaspin

            # wait for API to be ready
            with yaspin(text="Waiting for API..."):
                response = await check_api_is_ready()

            if len(single_query):
                print(f"NeuroML-AI (USER) >>> {single_query}\n\n")
                if single_query.lower() == "quit":
                    pass
                else:
                    with yaspin(text="Working ..."):
                        async with httpx.AsyncClient() as client:
                            response = await client.post(
                                "http://127.0.0.1:8005/query",
                                params={"query": single_query},
                                timeout=None
                            )
                            response_result = response.json().get("result")
                            print(f"NeuroML-AI (AI) >>> {response_result}\n\n")

            else:
                while (query := input("NeuroML-AI (USER) >>> ")) != "quit":
                    # we use checkpoints, so we don't need to store and reload the
                    # state ourselves
                    with yaspin(text="Working ..."):
                        async with httpx.AsyncClient() as client:
                            response = await client.post(
                                "http://127.0.0.1:8005/query", params={"query": query},
                                timeout=None
                            )
                            response_result = response.json().get("result")
                            print(f"NeuroML-AI (AI) >>> {response_result}\n\n")

        try:
            asyncio.run(cli_main())
        except KeyboardInterrupt:
            print("\nInterrupted. Exiting.")

    else:
        # streamlit app
        cwd = Path(__file__).parent
        with chdir(cwd):
            subprocess.run("streamlit run streamlit_ui.py".split())

    print("NeuroML-AI >>> Bye!")


if __name__ == "__main__":
    nml_ai_app()
